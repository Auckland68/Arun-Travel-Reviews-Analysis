{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the data is pre-processed:\n",
    "\n",
    "* Section 1 - pre-processing\n",
    "* Section 2 - text cleaning processes demonstrated on a toy dataset\n",
    "* Section 3 - text cleaning against sampled train, validation and test\n",
    "* Section 4 - text cleaning against full review dataset\n",
    "* Section 5 - text cleaning against dataset exploded to individual sentences\n",
    "\n",
    "Dataset to run notebook:\n",
    "\n",
    "* sampled_data.csv\n",
    "* all_reviews.csv\n",
    "\n",
    "Processed data saved to:\n",
    "\n",
    "* cleanedsampletext.csv   - cleaned sample text for model\n",
    "* fulldatasetcleaned.csv  - full review dataset cleaned\n",
    "* explodedsentencescleaned.csv - full reviews exploded to sentences and cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install language_check - note pyahocorasick had to also be installed using --add channels conda-forge and\n",
    "# conda install pyahocorasick. Java also installed in the path.\n",
    "# ! pip install --upgrade language-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install contractions\n",
    "#! pip install pyspellchecker \n",
    "#! pip install autocorrect\n",
    "#!pip install Gensim\n",
    "#! conda update pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\imoge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\imoge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\imoge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize,sent_tokenize\n",
    "import string\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "#from deepsegment import DeepSegment\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in balanced datasets from Post Attributes Base notebook\n",
    "df = pd.read_csv(\"sampled_data.csv\",index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Town</th>\n",
       "      <th>Type</th>\n",
       "      <th>Contributions</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>LocCode</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Spur</td>\n",
       "      <td>Food</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Pub/Bar</td>\n",
       "      <td>14</td>\n",
       "      <td>Very disappointing</td>\n",
       "      <td>Three of us ate on a quiet night. First of all...</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>British</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inglenook</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>10</td>\n",
       "      <td>Amazing place!!!</td>\n",
       "      <td>We had a lovely stay at the Inklenook ..room w...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name       Category     Town      Type  Contributions  \\\n",
       "0   The Spur           Food  Arundel   Pub/Bar             14   \n",
       "1  Inglenook  Accommodation   Bognor     Hotel             10   \n",
       "\n",
       "                Title                                             Review  \\\n",
       "0  Very disappointing  Three of us ate on a quiet night. First of all...   \n",
       "1   Amazing place!!!   We had a lovely stay at the Inklenook ..room w...   \n",
       "\n",
       "   Rating  Date  LocCode  Cuisine  Score  \n",
       "0       2   4.0      2.0  British      1  \n",
       "1       5   1.0      1.0        0      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Preprocessing the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing tasks:\n",
    "* join title and review text together into one column\n",
    "* set bad ratings of 1&2 to 1 and good of 4&5 to 0 and drop those rated 3\n",
    "* split reviews in dataframes for each category\n",
    "* sample 'good' reviews to match number of 'bad' to create balanced datasets\n",
    "* split into train, validation and testing sets for each category stratifying the y values so the same proportions appear\n",
    "  in each of train,val and test sets.\n",
    "* recombine the category feature dataframes to create combined feature dataframes for training, validation and test\n",
    "* concat the dataframes to create 3 balanced final dataframes with features and rating for accom, food and attractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select columns of interest, join title and review, drop unwanted columns and reset index\n",
    "def proc(df):\n",
    "    df = df[[\"Town\",\"Category\",\"Title\",\"Review\",\"Score\"]]\n",
    "    df[\"all_text\"] = df[\"Title\"] +\" \"+ df[\"Review\"]\n",
    "    df.drop(columns = [\"Title\",\"Review\"],axis = 1, inplace = True)\n",
    "    df.reset_index(inplace = True)\n",
    "    df.columns = [\"OrgInd\",\"Town\",\"Category\",\"Score\",\"all_text\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=proc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Text Cleaning against a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrgInd</th>\n",
       "      <th>Town</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1032</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>An excellent pub and restaurant An excellent p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>2406</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>Very good service Both my fiance and I have ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2591</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Food</td>\n",
       "      <td>1</td>\n",
       "      <td>Not bad but wouldn’t return  Over priced and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>1185</td>\n",
       "      <td>Littlehampton</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>0</td>\n",
       "      <td>Visit a friend We recently stayed at this hote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>1099</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>wonderful Yet again beautiful carvery meat coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>2488</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>Birthday bash  Tarrant Street can no longer be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1018</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>0</td>\n",
       "      <td>Wendy Excellent Hotel just outside Arundel, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>2508</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>Great friendly Place in Findon! Stopped for br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>778</td>\n",
       "      <td>Littlehampton</td>\n",
       "      <td>Food</td>\n",
       "      <td>1</td>\n",
       "      <td>Expensive Went for lunch with Grandson.\\nLimit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>2313</td>\n",
       "      <td>Littlehampton</td>\n",
       "      <td>Food</td>\n",
       "      <td>1</td>\n",
       "      <td>It’s was,...ok We came for a family meal, for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OrgInd           Town       Category  Score  \\\n",
       "1032    1032         Bognor           Food      0   \n",
       "2406    2406        Arundel           Food      0   \n",
       "2591    2591        Arundel           Food      1   \n",
       "1185    1185  Littlehampton  Accommodation      0   \n",
       "1099    1099         Bognor           Food      0   \n",
       "2488    2488        Arundel           Food      0   \n",
       "1018    1018        Arundel  Accommodation      0   \n",
       "2508    2508        Arundel           Food      0   \n",
       "778      778  Littlehampton           Food      1   \n",
       "2313    2313  Littlehampton           Food      1   \n",
       "\n",
       "                                               all_text  \n",
       "1032  An excellent pub and restaurant An excellent p...  \n",
       "2406  Very good service Both my fiance and I have ha...  \n",
       "2591  Not bad but wouldn’t return  Over priced and f...  \n",
       "1185  Visit a friend We recently stayed at this hote...  \n",
       "1099  wonderful Yet again beautiful carvery meat coo...  \n",
       "2488  Birthday bash  Tarrant Street can no longer be...  \n",
       "1018  Wendy Excellent Hotel just outside Arundel, bu...  \n",
       "2508  Great friendly Place in Findon! Stopped for br...  \n",
       "778   Expensive Went for lunch with Grandson.\\nLimit...  \n",
       "2313  It’s was,...ok We came for a family meal, for ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up test dataframe (uncomment to run a new sample)\n",
    "test = df.sample(10,random_state = 0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip newlines, whitespace and set to lowercase then strip newlines\n",
    "test['lower'] = test[\"all_text\"].apply(lambda x: x.replace('\\n',''))\n",
    "test['lower'] = test[\"lower\"].apply(lambda x: x.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'very good service both my fiance and i have had breakfast here a few times now and a mate and i have had a few pints before. but tonight we got some dinner and our server lucy where really nice to us and the legend in the kitchen, damien, made sure we where happy. thanks!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample review\n",
    "test[\"lower\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace words, and remove the 'read more', 'read less' tags (not relevant to example review)\n",
    "test['clean'] = test[\"lower\"].replace({'xmas': 'christmas'}, regex=True)\n",
    "test['clean'] = test.clean.str.replace(r'\\read less$', '', regex=True).str.strip()\n",
    "test['clean'] = test.clean.str.replace(r'\\read more$', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove other characters, split two words separated with slash, remove digits plus am and pm, \n",
    "# remove digits plus th or nd indicating dates, multiple full stops not removed by punctuation\n",
    "\n",
    "test['clean'] = test[\"clean\"].replace({'\\£':''}, regex = True)\n",
    "test['clean'] = test[\"clean\"].replace(r'\\/',\" \", regex=True)\n",
    "test['clean'] = test[\"clean\"].replace({'\\d+\\-\\d+':\"\"}, regex = True)\n",
    "test['clean'] = test[\"clean\"].replace({'\\d+\\w{2}':\"\"}, regex = True)\n",
    "test['clean'] = test[\"clean\"].replace({'\\.{3,}':\"\"}, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an excellent pub and restaurant an excellent pub and restaurant not a five star restaurant but offering excellent value and really good food with a very good selection of beers keep at the right temperature i have visited many times and have last found time to share my experience lloyd'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "test[\"clean\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions\n",
    "test[\"contracts\"] = test[\"clean\"].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an excellent pub and restaurant an excellent pub and restaurant not a five star restaurant but offering excellent value and really good food with a very good selection of beers keep at the right temperature i have visited many times and have last found time to share my experience lloyd'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"contracts\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "test[\"token\"] = test[\"contracts\"].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'excellent', 'pub', 'and', 'restaurant', 'an', 'excellent', 'pub', 'and', 'restaurant', 'not', 'a', 'five', 'star', 'restaurant', 'but', 'offering', 'excellent', 'value', 'and', 'really', 'good', 'food', 'with', 'a', 'very', 'good', 'selection', 'of', 'beers', 'keep', 'at', 'the', 'right', 'temperature', 'i', 'have', 'visited', 'many', 'times', 'and', 'have', 'last', 'found', 'time', 'to', 'share', 'my', 'experience', 'lloyd']"
     ]
    }
   ],
   "source": [
    "# Example review\n",
    "print(test[\"token\"].iloc[0], end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "punc = string.punctuation\n",
    "test[\"punct\"] = test[\"token\"].apply(lambda x: [word for word in x if word not in punc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'excellent', 'pub', 'and', 'restaurant', 'an', 'excellent', 'pub', 'and', 'restaurant', 'not', 'a', 'five', 'star', 'restaurant', 'but', 'offering', 'excellent', 'value', 'and', 'really', 'good', 'food', 'with', 'a', 'very', 'good', 'selection', 'of', 'beers', 'keep', 'at', 'the', 'right', 'temperature', 'i', 'have', 'visited', 'many', 'times', 'and', 'have', 'last', 'found', 'time', 'to', 'share', 'my', 'experience', 'lloyd']\n"
     ]
    }
   ],
   "source": [
    "# Example review\n",
    "print(test[\"punct\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers, except words that contain numbers.\n",
    "test[\"ex_num\"] = test[\"punct\"].apply(lambda x: [n for n in x if not n.isnumeric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non ascii characters\n",
    "test[\"ascii\"]= test[\"ex_num\"].apply(lambda x: [e for e in x if e.encode(\"ascii\",\"ignore\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'excellent', 'pub', 'and', 'restaurant', 'an', 'excellent', 'pub', 'and', 'restaurant', 'not', 'a', 'five', 'star', 'restaurant', 'but', 'offering', 'excellent', 'value', 'and', 'really', 'good', 'food', 'with', 'a', 'very', 'good', 'selection', 'of', 'beers', 'keep', 'at', 'the', 'right', 'temperature', 'i', 'have', 'visited', 'many', 'times', 'and', 'have', 'last', 'found', 'time', 'to', 'share', 'my', 'experience', 'lloyd']\n"
     ]
    }
   ],
   "source": [
    "# Example review\n",
    "print(test[\"ascii\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print stopwords list\n",
    "stop_words = set(stopwords.words('english')) \n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove and add words to stopwords list - expanding contractions eliminated most negation words like 'didn't already \n",
    "# but the word'not' is taken out as contractions convert to 'did not' etc.\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop_remove = [\"not\"]\n",
    "stop_left = [s for s in stop if s not in stop_remove]\n",
    "newStopWords = ['etc']\n",
    "stop_left.extend(newStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove common/stopwords\n",
    "test[\"no_stop\"] = test[\"ascii\"].apply(lambda x: [w for w in x if w not in stop_left])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'pub', 'restaurant', 'excellent', 'pub', 'restaurant', 'not', 'five', 'star', 'restaurant', 'offering', 'excellent', 'value', 'really', 'good', 'food', 'good', 'selection', 'beers', 'keep', 'right', 'temperature', 'visited', 'many', 'times', 'last', 'found', 'time', 'share', 'experience', 'lloyd']\n"
     ]
    }
   ],
   "source": [
    "# Example review\n",
    "print(test[\"no_stop\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(text_chunk):\n",
    "    spell = SpellChecker()\n",
    "    new_list = []\n",
    "    corrected = []\n",
    "    for word in text_chunk:\n",
    "        if spell.correction(word) != word:\n",
    "            new_word = spell.correction(word)\n",
    "            new_list.append(new_word)\n",
    "        else:\n",
    "            new_list.append(word)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where', 'is', 'the', 'best', 'restaurant']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run with example text to show corrections\n",
    "text_example_spelling = [\"where\", \"is\", \"the\", \"best\", \"restarant\"]\n",
    "spell_check(text_example_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032    [excellent, pub, restaurant, excellent, pub, r...\n",
       "2406    [good, service, fiance, breakfast, times, mate...\n",
       "2591    [not, bad, would, not, return, priced, food, d...\n",
       "1185    [visit, friend, recently, stayed, hotel, night...\n",
       "1099    [wonderful, yet, beautiful, carvery, meat, coo...\n",
       "2488    [birthday, bash, tarrant, street, longer, cons...\n",
       "1018    [wendy, excellent, hotel, outside, asunder, st...\n",
       "2508    [great, friendly, place, finden, stopped, brea...\n",
       "778     [expensive, went, lunch, grandson.limited, chi...\n",
       "2313    [ok, came, family, meal, time, day, week, woul...\n",
       "Name: no_stop, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to test dataframe\n",
    "test[\"no_stop\"].apply(lambda x: spell_check(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'pub', 'restaurant', 'excellent', 'pub', 'restaurant', 'not', 'five', 'star', 'restaurant', 'offering', 'excellent', 'value', 'really', 'good', 'food', 'good', 'selection', 'beers', 'keep', 'right', 'temperature', 'visited', 'many', 'times', 'last', 'found', 'time', 'share', 'experience', 'lloyd']\n"
     ]
    }
   ],
   "source": [
    "print(test[\"no_stop\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize to common root\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "test['lemma'] = test.no_stop.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrgInd</th>\n",
       "      <th>Town</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "      <th>all_text</th>\n",
       "      <th>lower</th>\n",
       "      <th>clean</th>\n",
       "      <th>contracts</th>\n",
       "      <th>token</th>\n",
       "      <th>punct</th>\n",
       "      <th>ex_num</th>\n",
       "      <th>ascii</th>\n",
       "      <th>no_stop</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1032</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>An excellent pub and restaurant An excellent p...</td>\n",
       "      <td>an excellent pub and restaurant an excellent p...</td>\n",
       "      <td>an excellent pub and restaurant an excellent p...</td>\n",
       "      <td>an excellent pub and restaurant an excellent p...</td>\n",
       "      <td>[an, excellent, pub, and, restaurant, an, exce...</td>\n",
       "      <td>[an, excellent, pub, and, restaurant, an, exce...</td>\n",
       "      <td>[an, excellent, pub, and, restaurant, an, exce...</td>\n",
       "      <td>[an, excellent, pub, and, restaurant, an, exce...</td>\n",
       "      <td>[excellent, pub, restaurant, excellent, pub, r...</td>\n",
       "      <td>[excellent, pub, restaurant, excellent, pub, r...</td>\n",
       "      <td>[(excellent, JJ), (pub, NN), (restaurant, NN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>2406</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Food</td>\n",
       "      <td>0</td>\n",
       "      <td>Very good service Both my fiance and I have ha...</td>\n",
       "      <td>very good service both my fiance and i have ha...</td>\n",
       "      <td>very good service both my fiance and i have ha...</td>\n",
       "      <td>very good service both my fiance and i have ha...</td>\n",
       "      <td>[very, good, service, both, my, fiance, and, i...</td>\n",
       "      <td>[very, good, service, both, my, fiance, and, i...</td>\n",
       "      <td>[very, good, service, both, my, fiance, and, i...</td>\n",
       "      <td>[very, good, service, both, my, fiance, and, i...</td>\n",
       "      <td>[good, service, fiance, breakfast, times, mate...</td>\n",
       "      <td>[good, service, fiance, breakfast, time, mate,...</td>\n",
       "      <td>[(good, JJ), (service, NN), (fiance, NN), (bre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OrgInd     Town Category  Score  \\\n",
       "1032    1032   Bognor     Food      0   \n",
       "2406    2406  Arundel     Food      0   \n",
       "\n",
       "                                               all_text  \\\n",
       "1032  An excellent pub and restaurant An excellent p...   \n",
       "2406  Very good service Both my fiance and I have ha...   \n",
       "\n",
       "                                                  lower  \\\n",
       "1032  an excellent pub and restaurant an excellent p...   \n",
       "2406  very good service both my fiance and i have ha...   \n",
       "\n",
       "                                                  clean  \\\n",
       "1032  an excellent pub and restaurant an excellent p...   \n",
       "2406  very good service both my fiance and i have ha...   \n",
       "\n",
       "                                              contracts  \\\n",
       "1032  an excellent pub and restaurant an excellent p...   \n",
       "2406  very good service both my fiance and i have ha...   \n",
       "\n",
       "                                                  token  \\\n",
       "1032  [an, excellent, pub, and, restaurant, an, exce...   \n",
       "2406  [very, good, service, both, my, fiance, and, i...   \n",
       "\n",
       "                                                  punct  \\\n",
       "1032  [an, excellent, pub, and, restaurant, an, exce...   \n",
       "2406  [very, good, service, both, my, fiance, and, i...   \n",
       "\n",
       "                                                 ex_num  \\\n",
       "1032  [an, excellent, pub, and, restaurant, an, exce...   \n",
       "2406  [very, good, service, both, my, fiance, and, i...   \n",
       "\n",
       "                                                  ascii  \\\n",
       "1032  [an, excellent, pub, and, restaurant, an, exce...   \n",
       "2406  [very, good, service, both, my, fiance, and, i...   \n",
       "\n",
       "                                                no_stop  \\\n",
       "1032  [excellent, pub, restaurant, excellent, pub, r...   \n",
       "2406  [good, service, fiance, breakfast, times, mate...   \n",
       "\n",
       "                                                  lemma  \\\n",
       "1032  [excellent, pub, restaurant, excellent, pub, r...   \n",
       "2406  [good, service, fiance, breakfast, time, mate,...   \n",
       "\n",
       "                                               pos_tags  \n",
       "1032  [(excellent, JJ), (pub, NN), (restaurant, NN),...  \n",
       "2406  [(good, JJ), (service, NN), (fiance, NN), (bre...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get parts of speech using NLTK\n",
    "test['pos_tags'] = test['no_stop'].apply(nltk.tag.pos_tag)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('excellent', 'JJ'), ('pub', 'NN'), ('restaurant', 'NN'), ('excellent', 'JJ'), ('pub', 'NN'), ('restaurant', 'NN'), ('not', 'RB'), ('five', 'CD'), ('star', 'NN'), ('restaurant', 'NN'), ('offering', 'NN'), ('excellent', 'JJ'), ('value', 'NN'), ('really', 'RB'), ('good', 'JJ'), ('food', 'NN'), ('good', 'JJ'), ('selection', 'NN'), ('beers', 'NNS'), ('keep', 'VB'), ('right', 'JJ'), ('temperature', 'NN'), ('visited', 'VBD'), ('many', 'JJ'), ('times', 'NNS'), ('last', 'JJ'), ('found', 'VBD'), ('time', 'NN'), ('share', 'NN'), ('experience', 'NN'), ('lloyd', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Example item\n",
    "print(test.pos_tags.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An excellent pub and restaurant An excellent pub and restaurant not a five star restaurant but offering excellent value and really good food with a very good selection of beers keep at the right temperature I have visited many times and have last found time to share my experience Lloyd \n",
      "\n",
      "['excellent', 'pub', 'restaurant', 'excellent', 'pub', 'restaurant', 'not', 'five', 'star', 'restaurant', 'offering', 'excellent', 'value', 'really', 'good', 'food', 'good', 'selection', 'beer', 'keep', 'right', 'temperature', 'visited', 'many', 'time', 'last', 'found', 'time', 'share', 'experience', 'lloyd'] \n",
      "\n",
      "[('excellent', 'JJ'), ('pub', 'NN'), ('restaurant', 'NN'), ('excellent', 'JJ'), ('pub', 'NN'), ('restaurant', 'NN'), ('not', 'RB'), ('five', 'CD'), ('star', 'NN'), ('restaurant', 'NN'), ('offering', 'NN'), ('excellent', 'JJ'), ('value', 'NN'), ('really', 'RB'), ('good', 'JJ'), ('food', 'NN'), ('good', 'JJ'), ('selection', 'NN'), ('beers', 'NNS'), ('keep', 'VB'), ('right', 'JJ'), ('temperature', 'NN'), ('visited', 'VBD'), ('many', 'JJ'), ('times', 'NNS'), ('last', 'JJ'), ('found', 'VBD'), ('time', 'NN'), ('share', 'NN'), ('experience', 'NN'), ('lloyd', 'NN')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test.all_text.iloc[0],\"\\n\")\n",
    "print(test.lemma.iloc[0],\"\\n\")\n",
    "print(test.pos_tags.iloc[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Text Cleaning Sentence for Demo in Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"Nice spacious room, clean and cmfortable beds, we stayed 3 nights and I couldn't fault anything! 😊 read less\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nice spacious room, clean and cmfortable beds, we stayed 3 nights and i couldn't fault anything! 😊 read less\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = example.strip().lower()\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nice spacious room, clean and cmfortable beds, we stayed 3 nights and i couldn't fault anything! 😊 \""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = example.replace('read less', '')\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nice spacious room, clean and cmfortable beds, we stayed 3 nights and i could not fault anything! 😊 '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = contractions.fix(example)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'spacious', 'room', ',', 'clean', 'and', 'cmfortable', 'beds', ',', 'we', 'stayed', '3', 'nights', 'and', 'i', 'could', 'not', 'fault', 'anything', '!', '😊']\n"
     ]
    }
   ],
   "source": [
    "example = nltk.word_tokenize(example)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'spacious', 'room', 'clean', 'and', 'cmfortable', 'beds', 'we', 'stayed', '3', 'nights', 'and', 'i', 'could', 'not', 'fault', 'anything', '😊']\n"
     ]
    }
   ],
   "source": [
    "example = [word for word in example if word not in punc]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'spacious', 'room', 'clean', 'and', 'cmfortable', 'beds', 'we', 'stayed', '3', 'nights', 'and', 'i', 'could', 'not', 'fault', 'anything']\n"
     ]
    }
   ],
   "source": [
    "example = [e for e in example if e.encode(\"ascii\",\"ignore\")]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'spacious', 'room', 'clean', 'and', 'cmfortable', 'beds', 'we', 'stayed', 'nights', 'and', 'i', 'could', 'not', 'fault', 'anything']\n"
     ]
    }
   ],
   "source": [
    "example = [n for n in example if not n.isnumeric()]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'spacious', 'room', 'clean', 'cmfortable', 'beds', 'stayed', 'nights', 'could', 'not', 'fault', 'anything']\n"
     ]
    }
   ],
   "source": [
    "example = [w for w in example if w not in stop_left]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(text_chunk):\n",
    "    spell = SpellChecker()\n",
    "    new_list = []\n",
    "    corrected = []\n",
    "    for word in text_chunk:\n",
    "        if spell.correction(word) != word:\n",
    "            new_word = spell.correction(word)\n",
    "            new_list.append(new_word)\n",
    "        else:\n",
    "            new_list.append(word)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'spacious', 'room', 'clean', 'comfortable', 'beds', 'stayed', 'nights', 'could', 'not', 'fault', 'anything']\n"
     ]
    }
   ],
   "source": [
    "example2 = spell_check(example)\n",
    "print(example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'spacious', 'room', 'clean', 'comfortable', 'bed', 'stayed', 'night', 'could', 'not', 'fault', 'anything']\n"
     ]
    }
   ],
   "source": [
    "example = lemmatize_text(example2)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nice', 'RB'), ('spacious', 'JJ'), ('room', 'NN'), ('clean', 'NN'), ('comfortable', 'JJ'), ('bed', 'NN'), ('stayed', 'VBD'), ('night', 'NN'), ('could', 'MD'), ('not', 'RB'), ('fault', 'VB'), ('anything', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.tag.pos_tag(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Text cleaning function applied to the sample dataset for use in the text models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pre-processing function based on the steps outlined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General pre-processing function with the above tasks to clean text -\n",
    "# spellchecker can replace words with incorrect words that do not make sense so can be uncommented to run if necessary\n",
    "\n",
    "def process(text):\n",
    "    \n",
    "       \n",
    "    # Replace newlines, strip whitespace and set to lowercase\n",
    "    text = text.apply(lambda x: x.replace('\\n',' '))\n",
    "    text = text.apply(lambda x: x.strip().lower())\n",
    "    \n",
    "    # Replace words, and remove the 'read more', 'read less' tags \n",
    "    text = text.apply(lambda x: x.replace('xmas','christmas'))\n",
    "    text = text.apply(lambda x: x.replace('\\nread less',\"\"))\n",
    "    text = text.apply(lambda x: x.replace('\\nread more',\"\"))\n",
    "       \n",
    "                  \n",
    "    # Clean other issues with text\n",
    "    text = text.replace({'\\£':\"\"}, regex = True) # remove pound sign\n",
    "    text = text.replace(r'\\/',\" \", regex=True) # split words separated with slash\n",
    "    text = text.replace({'\\d+\\-\\d+':\"\"}, regex = True) # remove digits\n",
    "    text = text.replace({'\\d+\\w{2}':\"\"}, regex = True) # remove number plus am, pm, th or nd\n",
    "    text = text.replace({'\\.{3,}':\"\"}, regex = True) # remove multiple full stops not removed by punctuation\n",
    "    \n",
    "   # Expand contractions\n",
    "    text = text.apply(lambda x: contractions.fix(x))\n",
    "\n",
    "    # Tokenize text\n",
    "    text = text.apply(lambda x: nltk.word_tokenize(x))\n",
    "    \n",
    "    # Remove punctuation\n",
    "    punc = string.punctuation\n",
    "    text = text.apply(lambda x: [word for word in x if word not in punc])\n",
    "             \n",
    "    # Remove numbers, except words that contain numbers.\n",
    "    text = text.apply(lambda x: [n for n in x if not n.isnumeric()])\n",
    "\n",
    "    # Remove non ascii characters\n",
    "    text = text.apply(lambda x: [e for e in x if e.encode(\"ascii\",\"ignore\")])\n",
    "\n",
    "    # Remove common/stopwords - extend and remove some words from the list as negation words might be important to retain\n",
    "    stop = stopwords.words('english')\n",
    "    stop_remove =[\"not\",\"don't\",\"didn't\",\"wasn't\",\"won't\",\"isn't\"]\n",
    "    stop1 = [elem for elem in stop if elem not in stop_remove] \n",
    "    add_stop = ['etc','read','read less','lot','butlins', 'bognor','regis','b',' i ','..','arundel castle','premier','inn','u',\n",
    "                'castle',\"year\",\"hilton\",\"time\",\"day\",\"shoreline\",\"oyster\",\"bay\",\"church farm\",\"hotham\",\"hotham park\",\n",
    "                \"hawk walk\",\"hawk\",\"arundel\",\"littlehampton\"]\n",
    "    stop1.extend(add_stop)\n",
    "    text = text.apply(lambda x: [w for w in x if w not in stop1])\n",
    "    \n",
    "    # Lemmatize to common root\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_text(text):\n",
    "        return [lemmatizer.lemmatize(w) for w in text]\n",
    "       \n",
    "    text = text.apply(lemmatize_text)\n",
    "    \n",
    "     # Spelling\n",
    "    def spell_correction(text):\n",
    "        spell = SpellChecker()\n",
    "        word_list = []\n",
    "        for word in text:\n",
    "            new_word = spell.correction(word)\n",
    "            if new_word != word:\n",
    "                word_list.append(new_word)\n",
    "            else: word_list.append(word)\n",
    "        return word_list      \n",
    "                \n",
    "    text = text.apply(spell_correction)\n",
    "    \n",
    "    # Convert list to string \n",
    "    text = text.apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # Remove trailing 'i'\n",
    "    text = text.apply(lambda x: x.replace(' i ',\"\"))\n",
    "    text = text.apply(lambda x: x.replace(' le ',\"\"))\n",
    "      \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function - uncomment to run as resource intensive\n",
    "df_cleaned = process(df[\"all_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make dataframe, name column then find parts of speech for text in that column\n",
    "def make_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = [\"text_clean\"]\n",
    "    df['pos'] = df[\"text_clean\"].apply(lambda x:nltk.tag.pos_tag(x.split()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function\n",
    "df_cleaned = make_df(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concat two dataframes and name columns\n",
    "def convert(df,df2):\n",
    "    df = pd.concat([df2,df],axis = 1)\n",
    "    columns = \"OrgInd\",\"Town\",\"Category\",\"Score\",\"Sent\",\"Sent_clean\",\"Pos\"\n",
    "    df.columns = (columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function\n",
    "df_cleaned = convert(df_cleaned,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrgInd</th>\n",
       "      <th>Town</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Sent_clean</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>Food</td>\n",
       "      <td>1</td>\n",
       "      <td>Very disappointing Three of us ate on a quiet ...</td>\n",
       "      <td>disappointing three u ate quiet night first go...</td>\n",
       "      <td>[(disappointing, JJ), (three, CD), (u, JJ), (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazing place!!!  We had a lovely stay at the ...</td>\n",
       "      <td>amazing place lovely stay inklenook room world...</td>\n",
       "      <td>[(amazing, JJ), (place, NN), (lovely, RB), (st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrgInd     Town       Category  Score  \\\n",
       "0       0  Arundel           Food      1   \n",
       "1       1   Bognor  Accommodation      0   \n",
       "\n",
       "                                                Sent  \\\n",
       "0  Very disappointing Three of us ate on a quiet ...   \n",
       "1  Amazing place!!!  We had a lovely stay at the ...   \n",
       "\n",
       "                                          Sent_clean  \\\n",
       "0  disappointing three u ate quiet night first go...   \n",
       "1  amazing place lovely stay inklenook room world...   \n",
       "\n",
       "                                                 Pos  \n",
       "0  [(disappointing, JJ), (three, CD), (u, JJ), (a...  \n",
       "1  [(amazing, JJ), (place, NN), (lovely, RB), (st...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send cleaned and combined dataframes to csv\n",
    "df_cleaned.to_csv(\"cleanedsampletext.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Text Pre-processing function applied to the total reviews dataset for use with topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in dataframe from Exploratory Data Analysis Notebook 1 - combined data (outliers not excluded)\n",
    "df_combined = pd.read_csv(\"all_reviews.csv\",index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10407, 12)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Town</th>\n",
       "      <th>Type</th>\n",
       "      <th>Location</th>\n",
       "      <th>Contributions</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>id</th>\n",
       "      <th>ReviewMonth</th>\n",
       "      <th>VisitMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butlins</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hitchin, United Kingdom</td>\n",
       "      <td>25</td>\n",
       "      <td>Nice break, shame about the accommodation...</td>\n",
       "      <td>We booked our 3 night stay from 27-30 December...</td>\n",
       "      <td>4</td>\n",
       "      <td>6804</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Butlins</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>69</td>\n",
       "      <td>Horrendous noise Oyster Bay</td>\n",
       "      <td>In Oyster Bay. Oh dear.\\n\\nVery poor sound ins...</td>\n",
       "      <td>1</td>\n",
       "      <td>1536</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name       Category    Town   Type                 Location  \\\n",
       "0  Butlins  Accommodation  Bognor  Hotel  Hitchin, United Kingdom   \n",
       "1  Butlins  Accommodation  Bognor  Hotel   London, United Kingdom   \n",
       "\n",
       "   Contributions                                         Title  \\\n",
       "0             25  Nice break, shame about the accommodation...   \n",
       "1             69                   Horrendous noise Oyster Bay   \n",
       "\n",
       "                                              Review  Rating    id  \\\n",
       "0  We booked our 3 night stay from 27-30 December...       4  6804   \n",
       "1  In Oyster Bay. Oh dear.\\n\\nVery poor sound ins...       1  1536   \n",
       "\n",
       "   ReviewMonth  VisitMonth  \n",
       "0           12          12  \n",
       "1           12          12  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Town</th>\n",
       "      <th>Rating</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice break, shame about the accommodation... W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrendous noise Oyster Bay In Oyster Bay. Oh ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category    Town  Rating  \\\n",
       "0  Accommodation  Bognor       4   \n",
       "1  Accommodation  Bognor       1   \n",
       "\n",
       "                                            all_text  \n",
       "0  Nice break, shame about the accommodation... W...  \n",
       "1  Horrendous noise Oyster Bay In Oyster Bay. Oh ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine title and review\n",
    "df_combined = df_combined[[\"Category\",\"Town\",\"Title\",\"Review\",\"Rating\"]]\n",
    "df_combined[\"all_text\"] = df_combined[\"Title\"] +\" \"+ df_combined[\"Review\"]\n",
    "df_combined.drop(columns = [\"Title\",\"Review\"],axis = 1, inplace = True)\n",
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function against the dataframe for reviews - UNCOMMENT TO RUN AS THIS TAKES A LONG TIME TO PROCESS!!\n",
    "df_combined[\"cleaned\"] = process(df_combined[\"all_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Town</th>\n",
       "      <th>Rating</th>\n",
       "      <th>all_text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice break, shame about the accommodation... W...</td>\n",
       "      <td>nice break shame accommodation booked night st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrendous noise Oyster Bay In Oyster Bay. Oh ...</td>\n",
       "      <td>horrendous noise oh dear poor sound insulation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category    Town  Rating  \\\n",
       "0  Accommodation  Bognor       4   \n",
       "1  Accommodation  Bognor       1   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  Nice break, shame about the accommodation... W...   \n",
       "1  Horrendous noise Oyster Bay In Oyster Bay. Oh ...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  nice break shame accommodation booked night st...  \n",
       "1  horrendous noise oh dear poor sound insulation...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file. Do not uncomment unless to overwrite the file\n",
    "df_combined.to_csv(\"fulldatasetcleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Text Pre-processing function applied to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrigInd</th>\n",
       "      <th>Category</th>\n",
       "      <th>Town</th>\n",
       "      <th>Rating</th>\n",
       "      <th>all_text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice break, shame about the accommodation... W...</td>\n",
       "      <td>nice break shame accommodation booked night st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrendous noise Oyster Bay In Oyster Bay. Oh ...</td>\n",
       "      <td>horrendous noise oh dear poor sound insulation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrigInd       Category    Town  Rating  \\\n",
       "0        0  Accommodation  Bognor       4   \n",
       "1        1  Accommodation  Bognor       1   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  Nice break, shame about the accommodation... W...   \n",
       "1  Horrendous noise Oyster Bay In Oyster Bay. Oh ...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  nice break shame accommodation booked night st...  \n",
       "1  horrendous noise oh dear poor sound insulation...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in saved dataset of reviews\n",
    "full_df = pd.read_csv(\"fulldatasetcleaned.csv\")\n",
    "full_df.columns = [\"OrigInd\",\"Category\",\"Town\",\"Rating\",\"all_text\",\"cleaned\"]\n",
    "full_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop cleaned column\n",
    "full_df.drop(columns = [\"cleaned\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrigInd</th>\n",
       "      <th>Category</th>\n",
       "      <th>Town</th>\n",
       "      <th>Rating</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice break, shame about the accommodation... W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrendous noise Oyster Bay In Oyster Bay. Oh ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrigInd       Category    Town  Rating  \\\n",
       "0        0  Accommodation  Bognor       4   \n",
       "1        1  Accommodation  Bognor       1   \n",
       "\n",
       "                                            all_text  \n",
       "0  Nice break, shame about the accommodation... W...  \n",
       "1  Horrendous noise Oyster Bay In Oyster Bay. Oh ...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each review into separate sentences, explode onto separate lines and check size\n",
    "full_df[\"sentences\"] = full_df[\"all_text\"].apply(lambda x: nltk.sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_exploded  = full_df.explode(\"sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60231, 6)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentences with the 'Read Less' tag removed\n",
    "full_df_exploded = full_df_exploded[full_df_exploded[\"sentences\"] != \"Read less\"]\n",
    "full_df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrigInd</th>\n",
       "      <th>Rating</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60231.000000</td>\n",
       "      <td>60231.000000</td>\n",
       "      <td>60231.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4631.481895</td>\n",
       "      <td>4.005612</td>\n",
       "      <td>84.022563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3135.820731</td>\n",
       "      <td>1.329433</td>\n",
       "      <td>66.467749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1780.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4421.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7360.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10406.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2094.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OrigInd        Rating           len\n",
       "count  60231.000000  60231.000000  60231.000000\n",
       "mean    4631.481895      4.005612     84.022563\n",
       "std     3135.820731      1.329433     66.467749\n",
       "min        0.000000      1.000000      1.000000\n",
       "25%     1780.000000      3.000000     42.000000\n",
       "50%     4421.000000      5.000000     70.000000\n",
       "75%     7360.500000      5.000000    107.000000\n",
       "max    10406.000000      5.000000   2094.000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the length of sentences\n",
    "full_df_exploded[\"len\"] = full_df_exploded[\"sentences\"].apply(lambda x: len(x))\n",
    "full_df_exploded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59956, 7)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with just one character such as exclamation marks\n",
    "full_df_exploded = full_df_exploded[full_df_exploded[\"len\"] > 1]\n",
    "full_df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 7)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find how many outliers there are in terms of length of sentence\n",
    "full_df_exploded[(np.abs(stats.zscore(full_df_exploded[\"len\"])) > 3)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrigInd</th>\n",
       "      <th>Category</th>\n",
       "      <th>Town</th>\n",
       "      <th>Rating</th>\n",
       "      <th>all_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Boring boggy butlins Well silver accommodation...</td>\n",
       "      <td>It’s ridiculous...adults are kept in line with...</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Angry We visited butlins bogner for my daughte...</td>\n",
       "      <td>Angry We visited butlins bogner for my daughte...</td>\n",
       "      <td>1693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Don't waste your time or money I am so angry w...</td>\n",
       "      <td>Don't waste your time or money I am so angry w...</td>\n",
       "      <td>2094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>5</td>\n",
       "      <td>Tots week Just got back from our 2nd tots week...</td>\n",
       "      <td>Tots week Just got back from our 2nd tots week...</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>665</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Arundel</td>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant ignore bad reviews  Well after readi...</td>\n",
       "      <td>Brilliant ignore bad reviews  Well after readi...</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Littlehampton</td>\n",
       "      <td>2</td>\n",
       "      <td>Half Term Break Site Complex not big enough fo...</td>\n",
       "      <td>Half Term Break Site Complex not big enough fo...</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1680</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Littlehampton</td>\n",
       "      <td>4</td>\n",
       "      <td>Lovely stay overall As we drove in the first a...</td>\n",
       "      <td>Lovely stay overall As we drove in the first a...</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>2080</td>\n",
       "      <td>Accommodation</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>3</td>\n",
       "      <td>Easter Break few minor ussues went here for an...</td>\n",
       "      <td>Easter Break few minor ussues went here for an...</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>8911</td>\n",
       "      <td>Food</td>\n",
       "      <td>Bognor</td>\n",
       "      <td>1</td>\n",
       "      <td>Wost company iv ever ordered from worst delive...</td>\n",
       "      <td>Wost company iv ever ordered from worst delive...</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      OrigInd       Category           Town  Rating  \\\n",
       "78         78  Accommodation         Bognor       1   \n",
       "98         98  Accommodation         Bognor       1   \n",
       "115       115  Accommodation         Bognor       1   \n",
       "314       314  Accommodation         Bognor       5   \n",
       "665       665  Accommodation        Arundel       5   \n",
       "999       999  Accommodation  Littlehampton       2   \n",
       "1680     1680  Accommodation  Littlehampton       4   \n",
       "2080     2080  Accommodation         Bognor       3   \n",
       "8911     8911           Food         Bognor       1   \n",
       "\n",
       "                                               all_text  \\\n",
       "78    Boring boggy butlins Well silver accommodation...   \n",
       "98    Angry We visited butlins bogner for my daughte...   \n",
       "115   Don't waste your time or money I am so angry w...   \n",
       "314   Tots week Just got back from our 2nd tots week...   \n",
       "665   Brilliant ignore bad reviews  Well after readi...   \n",
       "999   Half Term Break Site Complex not big enough fo...   \n",
       "1680  Lovely stay overall As we drove in the first a...   \n",
       "2080  Easter Break few minor ussues went here for an...   \n",
       "8911  Wost company iv ever ordered from worst delive...   \n",
       "\n",
       "                                              sentences   len  \n",
       "78    It’s ridiculous...adults are kept in line with...  1475  \n",
       "98    Angry We visited butlins bogner for my daughte...  1693  \n",
       "115   Don't waste your time or money I am so angry w...  2094  \n",
       "314   Tots week Just got back from our 2nd tots week...  1143  \n",
       "665   Brilliant ignore bad reviews  Well after readi...  1096  \n",
       "999   Half Term Break Site Complex not big enough fo...  1959  \n",
       "1680  Lovely stay overall As we drove in the first a...  1098  \n",
       "2080  Easter Break few minor ussues went here for an...  1344  \n",
       "8911  Wost company iv ever ordered from worst delive...  1029  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at review sentences over 1000 characters\n",
    "full_df_exploded[full_df_exploded[\"len\"] > 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost a thousand review sentences are considered to be outliers, these are retained for aspect extraction analysis as they still contain valuable information. There will always be reviews written without punctuation which stops the sentences being tokenized properly by nltk sentence tokenizer but it reflects the actual text input that is likely to be received. However, these reviews can be removed using the code in the cell below if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop long reviews that cannot be tokenized into sentences from the dataset - uncomment to run, long reviews kept otherwise\n",
    "#full_df = full_df[(np.abs(stats.zscore(full_df[\"len\"])) <3)]\n",
    "#full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use alternative library to try to split the long reviews into shorter ones based named entities\n",
    "# https://pypi.org/project/deepsegment/ NEEDS TENSORFLOW LOADED TO RUN - LOOK AT LATER\n",
    "\n",
    "#segmenter = DeepSegment('en')\n",
    "#segmenter.segment(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function against the dataframe for reviews - UNCOMMENT TO RUN AS THIS TAKES OVER AN HOUR TO PROCESS!!!\n",
    "full_df_exploded[\"cleaned\"] = process(full_df_exploded[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nice break shame accommodation booked night st...\n",
       "0    would never not really sure expect review eith...\n",
       "0    first impression not good we arrived parked ca...\n",
       "0    bearing mind people apartment obviously self-c...\n",
       "0    trip back forth one side resort balancing stuf...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_exploded[\"cleaned\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_exploded.to_csv(\"explodedsentencescleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
