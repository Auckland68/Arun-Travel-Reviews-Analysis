{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e19d6c7",
   "metadata": {},
   "source": [
    "# Notebook14 b) Combined Aspect Sentiment Model - Multi-class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483fbd2",
   "metadata": {},
   "source": [
    "This notebook brings together the best aspect models and the best sentiment model into one function, able to take in single raw reviews. This includes:\n",
    "\n",
    "* 3 multi-class aspect models\n",
    "* a binary sentiment model\n",
    "\n",
    "Current sample reviews taken from TripAdvisor for each category are used to test the model.\n",
    "\n",
    "* Section 1 - Import libraries\n",
    "* Section 2 - Import data and models\n",
    "* Section 3 - Functions\n",
    "* Section 4 - Testing the model\n",
    "\n",
    "\n",
    "\n",
    "Note:Notebook 14 b) repeats this model but takes account of neutral reviews. The results of Notebooks 14 a) and 14 b) are compared by using sample reviews of each category and assessing how well each performs. The best model is then run with another sample of raw text reviews and results examined in Notebook 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9811613",
   "metadata": {},
   "source": [
    "# Section 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc48f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Embedding,Dropout\n",
    "import contractions\n",
    "import pickle\n",
    "import joblib\n",
    "import string\n",
    "import ast\n",
    "import os\n",
    "from spellchecker import SpellChecker\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pandas import option_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78986ea7",
   "metadata": {},
   "source": [
    "# Section 2: Import data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf9282",
   "metadata": {},
   "source": [
    "### Import Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0d8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_tok(name):\n",
    "    with open(name, 'rb') as handle:\n",
    "        file = pickle.load(handle)\n",
    "        return file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6467573",
   "metadata": {},
   "source": [
    "### Import Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a75c2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenzier objects (all are TFIDF tokenizers except food which is Keras tokenizer object)\n",
    "accom_tok = open_tok(\"accom_tok.pickle\")\n",
    "food_tok = open_tok(\"food_tokenizer.pickle\")\n",
    "attract_tok = open_tok(\"attract_tok.pickle\")\n",
    "sent_tok = open_tok('tok_sent_multiclass.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937bf33",
   "metadata": {},
   "source": [
    "### Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3ff419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspect models (Accom - ML Model SVM TFIDF, Food - Neural Network Model, Attract = ML Model SVM TFIDF)\n",
    "model1 = joblib.load('best_model_accom.sav')\n",
    "model2 = load_model('food.h5')\n",
    "model3 = joblib.load('best_model_attract.sav')\n",
    "\n",
    "# Multiclass Sentiment model \n",
    "model4 = load_model(\"SentimentMultiNeural.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49014070",
   "metadata": {},
   "source": [
    "# Section 3: Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36810f76",
   "metadata": {},
   "source": [
    "### Function 1 - Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0561e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean sentences\n",
    "\n",
    "def process(text):\n",
    "    if text != []:\n",
    "        text = text.replace('\\n',' ')\n",
    "        text = text.strip().lower()\n",
    "        text = text.replace('xmas','christmas')\n",
    "        text = text.replace('\\Â£',\"\") \n",
    "        text = text.replace(r'\\/',\" \") \n",
    "        text = text.replace('\\d+\\-\\d+',\"\") \n",
    "        text = text.replace('\\d+\\w{2}',\"\") \n",
    "        text = text.replace('\\.{3,}',\"\") \n",
    "        text = text.replace(' i ',\"\")\n",
    "        text = text.replace(' le ',\"\")\n",
    "        text = contractions.fix(text)\n",
    "        text = nltk.word_tokenize(text)\n",
    "        punc = string.punctuation\n",
    "        text = [word for word in text if word not in punc]\n",
    "        text = [n for n in text if not n.isnumeric()]\n",
    "        text = [e for e in text if e.encode(\"ascii\",\"ignore\")]\n",
    "        stop = stopwords.words(\"english\")\n",
    "        stop_remove = [\"not\",\"don't\",\"didn't\",\"wasn't\",\"won't\",\"isn't\"]\n",
    "        stop1 = [w for w in stop if w not in stop_remove]\n",
    "        add_stop = ['etc','read','read less','lot','butlins', 'bognor','regis','b',' i ','..','arundel castle','premier','inn','u',\n",
    "                    'castle',\"year\",\"hilton\",\"time\",\"day\",\"shoreline\",\"oyster\",\"bay\",\"church farm\",\"hotham\",\"hotham park\",\n",
    "                    \"hawk walk\",\"hawk\",\"arundel\",\"littlehampton\"]\n",
    "        stop1.extend(add_stop)\n",
    "        text = [w for w in text if w not in stop1]\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = [lemmatizer.lemmatize(w) for w in text ]\n",
    "        spell = SpellChecker()\n",
    "        word_list = []\n",
    "        for w in text:\n",
    "            new = spell.correction(w)\n",
    "            if new != w:\n",
    "                word_list.append(new)\n",
    "            else:\n",
    "                word_list.append(w)\n",
    "            text = ' '.join(word_list) \n",
    "            \n",
    "                       \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e138af4",
   "metadata": {},
   "source": [
    "### Function 2 - Aspect Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "874539c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text):\n",
    "    text = word_tokenize(text)\n",
    "    text_pos = nltk.tag.pos_tag(text)\n",
    "    noun = [i[0] for i in text_pos if i[1].startswith('N')]\n",
    "    return noun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8f47a",
   "metadata": {},
   "source": [
    "### Function 3 - Noun Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b5768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract noun phrases from a review using TextBlob\n",
    "def phrase_extract(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747a818",
   "metadata": {},
   "source": [
    "### Function 4 - Encoding text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b904114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To padded sequences for the food aspects\n",
    "def encode(nouns,tokenizer):\n",
    "    x_s = tokenizer.texts_to_sequences(nouns)\n",
    "    x_w = pad_sequences(np.array(x_s, dtype = \"object\"), maxlen = 20,padding = \"post\", truncating = \"post\", value = 0.0)\n",
    "    return x_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae32b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To TFIDF vectorizer for all other category aspects and sentiment\n",
    "def encode2(text,vectorizer):\n",
    "    enc = vectorizer.transform(text)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e119c1",
   "metadata": {},
   "source": [
    "### Function 5 - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc479c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning model\n",
    "def predict1(model,X):\n",
    "    y_pred = model.predict(X)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e928bc8",
   "metadata": {},
   "source": [
    "### Function 6 - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0a63eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(text):\n",
    "    ss = sent_tok.texts_to_sequences(text)\n",
    "    ws = pad_sequences(np.array(ss, dtype = \"object\"), maxlen = 20,padding = \"post\", truncating = \"post\", value = 0.0)\n",
    "    sent_predict = pd.DataFrame(predict1(model4, ws))\n",
    "    y_sent_pred = pd.DataFrame(np.argmax(model4.predict(ws), axis=-1),columns = [\"S\"])\n",
    "    y_sent_pred[\"Sentiment\"] = y_sent_pred[\"S\"].apply(lambda x: label_sent.get(x))\n",
    "    return y_sent_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd2e40",
   "metadata": {},
   "source": [
    "### Function 6 - Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dddca167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run initial function\n",
    "def review_analyser(review,category):\n",
    "    \n",
    "    # Labels\n",
    "    label_accom = {0:'Entertainment',1:'Food',2:'Hotel',3:'Location',4:'Room',5:'Staff',6:'Value'}\n",
    "    label_food = {0:\"Food Quality\",1:\"Meal Exp\",2:\"Menu Choice\",3:\"Staff\",4:\"Value\",5:\"Visit Exp\"}\n",
    "    label_attract = {0:\"Activities\",1:\"Amenities\",2:\"History\",3:\"Nature\",4:\"Staff/Service\",5:\"Value\",6:\"Visit Exp\"}\n",
    "    label_sent = {0:\"Negative\",1:\"Neutral\",2:\"Positive\"}\n",
    "        \n",
    "       \n",
    "    # Models with weights\n",
    "    accom = model1\n",
    "    food = model2\n",
    "    attract = model3\n",
    "    sentiment = model4\n",
    "    \n",
    "    # Split review into sentences, extract noun_phrases and nouns and clean. Where extracted noun_phrases is an empty list\n",
    "    # the cleaned column is inserted instead.\n",
    "    sentences = pd.DataFrame(nltk.sent_tokenize(review),columns = [\"Sentences\"])\n",
    "    sentences[\"cleaned\"] = sentences[\"Sentences\"].apply(lambda x: process(x))\n",
    "    sentences[\"extract_noun_phrases\"] = sentences[\"cleaned\"].apply(phrase_extract)\n",
    "    sentences['extract_noun_phrases'] = np.where(sentences['extract_noun_phrases'].str.len() == 0, \n",
    "                                                 sentences['cleaned'], sentences['extract_noun_phrases'])\n",
    "    sentences[\"joined_phrases\"] = sentences[\"extract_noun_phrases\"].apply(lambda x: ' '.join(x) if type(x) != str else x)\n",
    "    sentences[\"extract_nouns\"] = sentences[\"cleaned\"].apply(extract)\n",
    "    sentences[\"joined_nouns\"] = sentences[\"extract_nouns\"].apply(lambda x: ' '.join(x))\n",
    "    sentences[\"joined_nouns\"] = sentences[\"joined_nouns\"].apply(lambda x: \"general\" if x == \"\" else x)\n",
    "    \n",
    "    # Predict aspects and sentiment for food\n",
    "    if category == \"food\":\n",
    "        s = food_tok.texts_to_sequences(sentences[\"joined_nouns\"])\n",
    "        w = pad_sequences(np.array(s, dtype = \"object\"), maxlen = 20,padding = \"post\", truncating = \"post\", value = 0.0)\n",
    "        predict = predict1(model2,w)\n",
    "        y_pred_class = np.argmax(model2.predict(w), axis=-1)\n",
    "        y_pred_class = pd.DataFrame(y_pred_class, columns = [\"A\"])\n",
    "        y_pred_class[\"Aspect\"] = y_pred_class[\"A\"].apply(lambda x: label_food.get(x))\n",
    "        \n",
    "        y_sent_pred = sent(sentences[\"joined_phrases\"])\n",
    "        sentiment_summary = pd.concat([sentences[\"Sentences\"],y_sent_pred],axis = 1) \n",
    "                         \n",
    "    # Predict aspects and sentiment for accommodation\n",
    "    elif category == \"accommodation\":\n",
    "        encoded = accom_tok.transform(sentences[\"joined_nouns\"])\n",
    "        predict = predict1(model1,encoded)  \n",
    "        y_pred_class = pd.DataFrame(predict, columns = [\"A\"])\n",
    "        y_pred_class[\"Predicted Aspect\"] = y_pred_class[\"A\"].apply(lambda x: label_accom.get(x))\n",
    "        \n",
    "        y_sent_pred = sent(sentences[\"joined_phrases\"])\n",
    "        sentiment_summary = pd.concat([sentences[\"Sentences\"],y_sent_pred],axis = 1) \n",
    "     \n",
    "    # Predict aspects and sentiment for attractions\n",
    "    else:\n",
    "        encoded = attract_tok.transform(sentences[\"joined_nouns\"])\n",
    "        predict = predict1(model3,encoded)\n",
    "        y_pred_class = pd.DataFrame(predict, columns = [\"A\"])\n",
    "        y_pred_class[\"Predicted Aspect\"] = y_pred_class[\"A\"].apply(lambda x: label_attract.get(x))\n",
    "\n",
    "        y_sent_pred = sent(sentences[\"joined_phrases\"])\n",
    "        sentiment_summary = pd.concat([sentences[\"Sentences\"],y_sent_pred],axis = 1) \n",
    "       \n",
    "    aspect_sentiment = pd.concat([y_pred_class,sentiment_summary],axis = 1) \n",
    "        \n",
    "    with option_context('display.max_colwidth', 100):\n",
    "        display(aspect_sentiment)\n",
    "              \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481c977",
   "metadata": {},
   "source": [
    "# Section 4: Testing the Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af23e3",
   "metadata": {},
   "source": [
    "## Sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "70ad2de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Went for a birthday celebration they fail to tell you when you book that they no longer serve alcohol even though we have been long term customers. It was suggested we go to a nearby supermarket and purchase our own alcohol, not really ideal on a night out. Prices have gone up massively maybe to compensate for not selling alcohol anymore. Would not recommend, we left and found Magna Indian restaurant which was reasonable accommodating and lovely food\n"
     ]
    }
   ],
   "source": [
    "# Food Review\n",
    "review_test = \"Went for a birthday celebration they fail to tell you when you book that they no longer serve alcohol even though we have been long term customers. It was suggested we go to a nearby supermarket and purchase our own alcohol, not really ideal on a night out. Prices have gone up massively maybe to compensate for not selling alcohol anymore. Would not recommend, we left and found Magna Indian restaurant which was reasonable accommodating and lovely food\"\n",
    "print(review_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b3d6bd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>S</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Meal Exp</td>\n",
       "      <td>Went for a birthday celebration they fail to tell you when you book that they no longer serve al...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Visit Exp</td>\n",
       "      <td>It was suggested we go to a nearby supermarket and purchase our own alcohol, not really ideal on...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Value</td>\n",
       "      <td>Prices have gone up massively maybe to compensate for not selling alcohol anymore.</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Food Quality</td>\n",
       "      <td>Would not recommend, we left and found Magna Indian restaurant which was reasonable accommodatin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A        Aspect  \\\n",
       "0  1      Meal Exp   \n",
       "1  5     Visit Exp   \n",
       "2  4         Value   \n",
       "3  0  Food Quality   \n",
       "\n",
       "                                                                                             Sentences  \\\n",
       "0  Went for a birthday celebration they fail to tell you when you book that they no longer serve al...   \n",
       "1  It was suggested we go to a nearby supermarket and purchase our own alcohol, not really ideal on...   \n",
       "2                   Prices have gone up massively maybe to compensate for not selling alcohol anymore.   \n",
       "3  Would not recommend, we left and found Magna Indian restaurant which was reasonable accommodatin...   \n",
       "\n",
       "   S Sentiment  \n",
       "0  0  Negative  \n",
       "1  1   Neutral  \n",
       "2  0  Negative  \n",
       "3  1   Neutral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_analyser(review_test,\"food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ddfba1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room absolutely stunk of cigarettes. Avoid. Nowhere to eat locally either. Tried restaurant but told had to wait 2 hours for table despite no one sitting outside on a sunny day and only 2 people that I could see inside.Asked reception and told restaurant 15 min walk away (it wasnt) but may hv to book. No offer phone up to see if table free!\n"
     ]
    }
   ],
   "source": [
    "# Accommodation Review\n",
    "review_test1 = \"Room absolutely stunk of cigarettes. Avoid. Nowhere to eat locally either. Tried restaurant but told had to wait 2 hours for table despite no one sitting outside on a sunny day and only 2 people that I could see inside.Asked reception and told restaurant 15 min walk away (it wasnt) but may hv to book. No offer phone up to see if table free!\"\n",
    "print(review_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a7a0c6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>Predicted Aspect</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>S</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Room</td>\n",
       "      <td>Room absolutely stunk of cigarettes.</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Avoid.</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Nowhere to eat locally either.</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Food</td>\n",
       "      <td>Tried restaurant but told had to wait 2 hours for table despite no one sitting outside on a sunn...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>No offer phone up to see if table free!</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A Predicted Aspect  \\\n",
       "0  4             Room   \n",
       "1  0    Entertainment   \n",
       "2  0    Entertainment   \n",
       "3  1             Food   \n",
       "4  0    Entertainment   \n",
       "\n",
       "                                                                                             Sentences  \\\n",
       "0                                                                 Room absolutely stunk of cigarettes.   \n",
       "1                                                                                               Avoid.   \n",
       "2                                                                       Nowhere to eat locally either.   \n",
       "3  Tried restaurant but told had to wait 2 hours for table despite no one sitting outside on a sunn...   \n",
       "4                                                              No offer phone up to see if table free!   \n",
       "\n",
       "   S Sentiment  \n",
       "0  1   Neutral  \n",
       "1  1   Neutral  \n",
       "2  1   Neutral  \n",
       "3  0  Negative  \n",
       "4  2  Positive  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_analyser(review_test1,\"accommodation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "77ff1418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the outskirts of Bognor this park is very pleasant with a large cafe and an excellent crazy golf course. It also has a miniature railway and a boating lake but both were closed on the afternoon of our visit. However, we walked around the main pathways and saw a few squirrels. A very pleasant place for a short visit.\n"
     ]
    }
   ],
   "source": [
    "# Attraction Review\n",
    "review_test2 = \"On the outskirts of Bognor this park is very pleasant with a large cafe and an excellent crazy golf course. It also has a miniature railway and a boating lake but both were closed on the afternoon of our visit. However, we walked around the main pathways and saw a few squirrels. A very pleasant place for a short visit.\"\n",
    "print(review_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9e56cf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>Predicted Aspect</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>S</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Activities</td>\n",
       "      <td>On the outskirts of Bognor this park is very pleasant with a large cafe and an excellent crazy g...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Visit Exp</td>\n",
       "      <td>It also has a miniature railway and a boating lake but both were closed on the afternoon of our ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Visit Exp</td>\n",
       "      <td>However, we walked around the main pathways and saw a few squirrels.</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Visit Exp</td>\n",
       "      <td>A very pleasant place for a short visit.</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A Predicted Aspect  \\\n",
       "0  0       Activities   \n",
       "1  6        Visit Exp   \n",
       "2  6        Visit Exp   \n",
       "3  6        Visit Exp   \n",
       "\n",
       "                                                                                             Sentences  \\\n",
       "0  On the outskirts of Bognor this park is very pleasant with a large cafe and an excellent crazy g...   \n",
       "1  It also has a miniature railway and a boating lake but both were closed on the afternoon of our ...   \n",
       "2                                 However, we walked around the main pathways and saw a few squirrels.   \n",
       "3                                                             A very pleasant place for a short visit.   \n",
       "\n",
       "   S Sentiment  \n",
       "0  2  Positive  \n",
       "1  2  Positive  \n",
       "2  1   Neutral  \n",
       "3  0  Negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_analyser(review_test2, \"attractions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
